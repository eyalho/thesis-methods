{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 20\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True,  download=True, transform=transform)\n",
    "test_data  = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_data,  batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_labels = torch.tensor(\n",
    "  [\n",
    "    [0.0788, 0.1254, 0.0268, 0.2183, 0.3003, 0.3279, 0.0510, 0.0439, 0.3552,\n",
    "      0.0749, 0.0862, 0.3351, 0.0506, 0.1168, 0.1643, 0.1960, 0.2681, 0.2267,\n",
    "      0.1867, 0.3841, 0.0528, 0.1355, 0.0233, 0.0842, 0.2447], # digit 0\n",
    "    [0.0751, 0.1258, 0.2656, 0.0132, 0.0048, 0.0459, 0.0123, 0.0921, 0.0722,\n",
    "      0.4720, 0.0563, 0.0858, 0.1946, 0.0289, 0.0549, 0.0889, 0.0180, 0.0328,\n",
    "      0.2810, 0.0050, 0.2128, 0.0508, 0.6535, 0.0418, 0.2278],  # digit 1\n",
    "    [0.2016, 0.2286, 0.0246, 0.0350, 0.0284, 0.0113, 0.5795, 0.0695, 0.0989,\n",
    "      0.0515, 0.5213, 0.0253, 0.2721, 0.0178, 0.0095, 0.0061, 0.0243, 0.0309,\n",
    "      0.1076, 0.0285, 0.2499, 0.1712, 0.0729, 0.3033, 0.0366],  # digit 2\n",
    "    [0.0282, 0.1384, 0.0564, 0.0931, 0.0529, 0.0337, 0.1164, 0.1348, 0.0838,\n",
    "      0.0159, 0.3105, 0.0114, 0.1378, 0.0378, 0.0598, 0.7858, 0.0471, 0.1663,\n",
    "      0.0565, 0.0347, 0.0680, 0.2686, 0.0610, 0.2588, 0.0746],  # digit 3\n",
    "    [0.0368, 0.1348, 0.6532, 0.1854, 0.0323, 0.1109, 0.1187, 0.0222, 0.0124,\n",
    "      0.1473, 0.2992, 0.0402, 0.0864, 0.2666, 0.0860, 0.0477, 0.2516, 0.2643,\n",
    "      0.0793, 0.1082, 0.3297, 0.0828, 0.0344, 0.0016, 0.1499],  # digit 4\n",
    "    [0.4528, 0.1523, 0.0251, 0.0511, 0.1991, 0.0561, 0.1557, 0.6983, 0.0731,\n",
    "      0.1860, 0.0884, 0.0276, 0.1971, 0.1252, 0.1858, 0.0104, 0.0453, 0.1107,\n",
    "      0.0252, 0.0585, 0.0470, 0.1628, 0.1336, 0.0263, 0.1031],  # digit 5\n",
    "    [0.1442, 0.0414, 0.0260, 0.1051, 0.1011, 0.0484, 0.0940, 0.0715, 0.0459,\n",
    "      0.5043, 0.0312, 0.0336, 0.1456, 0.5837, 0.2772, 0.0289, 0.4086, 0.0950,\n",
    "      0.1037, 0.0274, 0.0142, 0.0024, 0.0353, 0.2247, 0.0419],  # digit 6\n",
    "    [0.0253, 0.0100, 0.0521, 0.1290, 0.1214, 0.1809, 0.0092, 0.0036, 0.0223,\n",
    "      0.0029, 0.0192, 0.0209, 0.5189, 0.1902, 0.2108, 0.0400, 0.0302, 0.1245,\n",
    "      0.4193, 0.0728, 0.0449, 0.5350, 0.2411, 0.1886, 0.0111],  # digit 7\n",
    "    [0.1489, 0.7321, 0.0011, 0.0065, 0.0215, 0.0462, 0.1617, 0.0958, 0.1073,\n",
    "      0.0546, 0.0956, 0.0459, 0.0222, 0.1168, 0.2183, 0.0008, 0.0317, 0.0330,\n",
    "      0.0749, 0.3990, 0.0605, 0.1267, 0.3394, 0.1195, 0.0142],  # digit 8\n",
    "    [0.5247, 0.0227, 0.2495, 0.0037, 0.1025, 0.2442, 0.0776, 0.0051, 0.0561,\n",
    "      0.0639, 0.0168, 0.1553, 0.1897, 0.0241, 0.0676, 0.1564, 0.0050, 0.0364,\n",
    "      0.0179, 0.0769, 0.0420, 0.0796, 0.2302, 0.5864, 0.2758]  # digit 9\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "  return (1 - nn.CosineSimilarity(eps=1e-6)(x, y)).sum() / x.size(0)\n",
    "\n",
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(MNIST_Classifier, self).__init__()\n",
    "      \n",
    "      self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "      self.conv2 = nn.Conv2d(16, 8, 3, padding=2)\n",
    "      self.conv3 = nn.Conv2d(8,  1, 3, padding=2)\n",
    "\n",
    "      self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "      x = self.pool(F.relu(self.conv1(x)))\n",
    "      x = self.pool(F.relu(self.conv2(x)))\n",
    "      x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "      return x\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training set\n",
    "\n",
    "def sort_train_loader(train_loader, sample_size = 10, seed = 0):\n",
    "  original_train_loader = False\n",
    "\n",
    "  if 'train_labels' in set(dir(train_loader.dataset)):\n",
    "    original_train_loader = True\n",
    "    \n",
    "  if original_train_loader:\n",
    "    train_targets = train_loader.dataset.train_labels\n",
    "  else:\n",
    "    train_targets = train_loader.dataset.tensors[1]\n",
    "\n",
    "  train_loader_digits = []\n",
    "\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  for i in range(vector_labels.size(0)):\n",
    "    if original_train_loader:\n",
    "      ds = train_loader.dataset.train_data[train_targets == i].unsqueeze(1).float() / 255\n",
    "    else:\n",
    "      ds = train_loader.dataset.tensors[0][train_targets == i].unsqueeze(1).float() / 255\n",
    "\n",
    "    train_loader_digits.append(\n",
    "      torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "          ds[torch.randperm(ds.size(0))][0:sample_size],\n",
    "          train_targets[train_targets == i][0:sample_size]\n",
    "        ),\n",
    "        batch_size  = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle     = True\n",
    "      )\n",
    "    )\n",
    "  \n",
    "  return train_loader_digits\n",
    "\n",
    "train_loader_digits = sort_train_loader(train_loader, sample_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for digit 0 (training set size 10)\n",
      "Best loss for 0 digit: 0.205097\n",
      "Training the model for digit 1 (training set size 10)\n",
      "Best loss for 1 digit: 0.191442\n",
      "Training the model for digit 2 (training set size 10)\n",
      "Best loss for 2 digit: 0.224210\n",
      "Training the model for digit 3 (training set size 10)\n",
      "Best loss for 3 digit: 0.230173\n",
      "Training the model for digit 4 (training set size 10)\n",
      "Best loss for 4 digit: 0.242070\n",
      "Training the model for digit 5 (training set size 10)\n",
      "Best loss for 5 digit: 0.206711\n",
      "Training the model for digit 6 (training set size 10)\n",
      "Best loss for 6 digit: 0.816394\n",
      "Training the model for digit 7 (training set size 10)\n",
      "Best loss for 7 digit: 0.275613\n",
      "Training the model for digit 8 (training set size 10)\n",
      "Best loss for 8 digit: 0.154728\n",
      "Training the model for digit 9 (training set size 10)\n",
      "Best loss for 9 digit: 0.305659\n"
     ]
    }
   ],
   "source": [
    "# Training initial model\n",
    "\n",
    "import copy\n",
    "\n",
    "def train_model(model, train_loader_digit, opt, n_epochs=20):\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data in train_loader_digit:\n",
    "      images, labels = data\n",
    "\n",
    "      opt.zero_grad()\n",
    "\n",
    "      out = model(images.to(device)).view(images.size(0), 25)\n",
    "              \n",
    "      loss = loss_fn(out, torch.tensor([vector_labels[i].tolist() for i in labels]).to(device)) * images.size(0)\n",
    "                  \n",
    "      loss.backward()\n",
    "\n",
    "      opt.step()\n",
    "\n",
    "      train_loss += (loss.item() * images.size(0))\n",
    "\n",
    "    train_loss = train_loss / train_loader_digit.dataset.tensors[0].size(0)\n",
    "\n",
    "  return train_loss\n",
    "\n",
    "def choose_best_model(digit=0, epochs=50, min_loss=0.35, max_tries=100):\n",
    "  try_num = 0\n",
    "  best_model = None\n",
    "  best_loss = None\n",
    "\n",
    "  while try_num < max_tries:\n",
    "    model  = MNIST_Classifier().to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "    model.init_weights()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss = train_model(model, train_loader_digits[digit], opt, epochs)\n",
    "\n",
    "    if loss < min_loss:\n",
    "      best_model = copy.deepcopy(model)\n",
    "      \n",
    "      best_loss = loss\n",
    "\n",
    "      break\n",
    "\n",
    "    if best_loss is None or loss < best_loss:\n",
    "      best_model = copy.deepcopy(model)\n",
    "\n",
    "      best_loss = loss\n",
    "\n",
    "    try_num += 1\n",
    "\n",
    "  return best_model, best_loss\n",
    "\n",
    "def train_digit_models(epochs = 50, max_tries = 50, min_loss = 0.35, seed = 0):\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  digit_models = []\n",
    "\n",
    "  for digit in range(10): \n",
    "    print('Training the model for digit {} (training set size {})'.format(digit, train_loader_digits[digit].dataset.tensors[0].size(0)))\n",
    "\n",
    "    model, loss = choose_best_model(digit, epochs=epochs, min_loss=min_loss, max_tries=max_tries)\n",
    "\n",
    "    print('Best loss for {} digit: {:.6f}'.format(digit, loss))\n",
    "\n",
    "    digit_models.append(copy.deepcopy(model))\n",
    "\n",
    "  return digit_models\n",
    "\n",
    "vector_labels = vector_labels[torch.randperm(vector_labels.size(0))]\n",
    "\n",
    "digit_models = train_digit_models(epochs = 50, max_tries = 50, min_loss = 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified 13 images\n",
      "Classified 1461 images\n",
      "Classified 2929 images\n",
      "Classified 4372 images\n",
      "Classified 5817 images\n",
      "Classified 7297 images\n",
      "Classified 8737 images\n",
      "Classified 10168 images\n",
      "Classified 11567 images\n",
      "Classified 13040 images\n",
      "Classified 14474 images\n",
      "Classified 15899 images\n",
      "Classified 17362 images\n",
      "Classified 18800 images\n",
      "Classified 20223 images\n",
      "Classified 21650 images\n",
      "Classified 23104 images\n",
      "Classified 24556 images\n",
      "Classified 26033 images\n",
      "Classified 27484 images\n",
      "Classified 28931 images\n",
      "Classified 30380 images\n",
      "Classified 31828 images\n",
      "Classified 33275 images\n",
      "Classified 34752 images\n",
      "Classified 36211 images\n",
      "Classified 37635 images\n",
      "Classified 39061 images\n",
      "Classified 40496 images\n",
      "Classified 41949 images\n",
      "Total classified images 43406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([5458, 6546, 3210, 4086, 4052, 4908, 2814, 6265, 3096, 2971]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification of digit images\n",
    "def classify_images(images, labels):\n",
    "  loss = []\n",
    "\n",
    "  for j in range(len(digit_models)):\n",
    "    out = digit_models[j](images.to(device)).view(images.size(0), 25)\n",
    "\n",
    "    loss.append(nn.CosineSimilarity(eps=1e-6)(out, torch.tensor([vector_labels[i].tolist() for i in labels]).to(device)).tolist())\n",
    "\n",
    "  return loss\n",
    "\n",
    "classified_cnt = 0\n",
    "\n",
    "min_similarity = 0.895\n",
    "\n",
    "i = 0\n",
    "\n",
    "selected_images = []\n",
    "selected_labels = []\n",
    "\n",
    "for data in train_loader:\n",
    "  images, labels = data \n",
    "\n",
    "  loss = classify_images(images, labels)\n",
    "\n",
    "  loss_tr = torch.tensor(loss).t()\n",
    "\n",
    "  selected_ind = torch.arange(images.size(0))[(loss_tr > min_similarity).any(1)]\n",
    "\n",
    "  selected_images.append(images[selected_ind])\n",
    "  selected_labels.append(loss_tr[selected_ind,:].argsort(1)[:,-1])\n",
    "  \n",
    "  if (loss_tr[selected_ind,:].argsort(1)[:,-1] - labels[selected_ind]).sum() > 0:\n",
    "    print(loss_tr[selected_ind,:].argsort(1)[:,-1])\n",
    "    print(labels[selected_ind])\n",
    "  else:\n",
    "    classified_cnt += selected_ind.size(0)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "      print('Classified {} images'.format(classified_cnt))\n",
    "\n",
    "  i += 1\n",
    "\n",
    "print('Total classified images {}'.format(classified_cnt))\n",
    "\n",
    "selected_images = torch.cat(selected_images) * 255\n",
    "selected_labels = torch.cat(selected_labels)\n",
    "\n",
    "new_train_loader = torch.utils.data.DataLoader(\n",
    "  torch.utils.data.TensorDataset(\n",
    "    selected_images.squeeze(1),\n",
    "    selected_labels\n",
    "  ),\n",
    "  batch_size  = batch_size,\n",
    "  num_workers = num_workers,\n",
    "  shuffle     = True\n",
    ")\n",
    "\n",
    "selected_labels.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for digit 0 (training set size 500)\n",
      "Best loss for 0 digit: 0.156533\n",
      "Training the model for digit 1 (training set size 500)\n",
      "Best loss for 1 digit: 0.123693\n",
      "Training the model for digit 2 (training set size 500)\n",
      "Best loss for 2 digit: 0.445301\n",
      "Training the model for digit 3 (training set size 500)\n",
      "Best loss for 3 digit: 0.377200\n",
      "Training the model for digit 4 (training set size 500)\n",
      "Best loss for 4 digit: 0.211388\n",
      "Training the model for digit 5 (training set size 500)\n",
      "Best loss for 5 digit: 0.347308\n",
      "Training the model for digit 6 (training set size 500)\n",
      "Best loss for 6 digit: 0.313432\n",
      "Training the model for digit 7 (training set size 500)\n",
      "Best loss for 7 digit: 0.791574\n",
      "Training the model for digit 8 (training set size 500)\n",
      "Best loss for 8 digit: 1.053649\n",
      "Training the model for digit 9 (training set size 500)\n",
      "Best loss for 9 digit: 0.221755\n"
     ]
    }
   ],
   "source": [
    "# Tranining the model for classification\n",
    "train_loader_digits = sort_train_loader(new_train_loader, sample_size = 500, seed = 1)\n",
    "\n",
    "vector_labels = vector_labels[torch.randperm(vector_labels.size(0))]\n",
    "\n",
    "digit_models = train_digit_models(epochs = 20, max_tries = 10, min_loss = 0.55, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: miss-classified 2 in 10000 images\n",
      "Train set: miss-classified 7 in 60000 images\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "def eval_model(dataset_loader):\n",
    "  miss_classified = 0\n",
    "\n",
    "  for data in dataset_loader:\n",
    "    images, labels = data\n",
    "    \n",
    "    loss = []\n",
    "\n",
    "    for j in range(len(digit_models)):\n",
    "      out = digit_models[j](images.to(device)).view(images.size(0), 25)\n",
    "\n",
    "      loss.append(nn.CosineSimilarity(eps=1e-6)(out, torch.tensor([vector_labels[i].tolist() for i in labels]).to(device)).tolist())\n",
    "\n",
    "    miss_classified += (torch.tensor(loss).t().argsort()[:,-1] != labels).int().sum()\n",
    "  \n",
    "  return miss_classified\n",
    "\n",
    "print('Test set: miss-classified {} in {} images'.format(eval_model(test_loader), test_loader.dataset.test_data.size(0)))\n",
    "\n",
    "print('Train set: miss-classified {} in {} images'.format(eval_model(train_loader), train_loader.dataset.train_data.size(0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
